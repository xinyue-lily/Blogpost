{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blogpost5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJZ4kfMAq5c3BQDdUyXjc7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyue-lily/Blogpost/blob/main/blogpost5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8O-1Fs709yOe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras import utils "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location of data\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "# download the data and extract it\n",
        "path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "# construct paths\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "# parameters for datasets\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "# construct train and validation datasets \n",
        "train_dataset = utils.image_dataset_from_directory(train_dir,\n",
        "                           shuffle=True,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           image_size=IMG_SIZE)\n",
        "\n",
        "validation_dataset = utils.image_dataset_from_directory(validation_dir,\n",
        "                           shuffle=True,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           image_size=IMG_SIZE)\n",
        "\n",
        "# construct the test dataset by taking every 5th observation out of the validation dataset\n",
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENDsrsCR988C",
        "outputId": "ef997379-839d-434c-bb90-969d995ab378"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "PHecJUCZ-vNT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.class_names\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "#for images, labels in train_dataset.take(1):\n",
        "#  for i in range(6):\n",
        "#    if labels[i]==1:\n",
        "#      ax = plt.subplot(2, 3, i + 1)\n",
        "#      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#    plt.title(class_names[labels[i]])\n",
        "#plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "5NSVbPVW_Sw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}